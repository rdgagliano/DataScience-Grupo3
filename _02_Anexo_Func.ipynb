{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import maxsize #para imprimir arrays completos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing #para normalizar datos\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos particulares del data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recorre el data frame en su totalidad y modifica las etiquetas que representan los valores por textos mas comprensibles. \n",
    "#Ejemplo: para la columna cap-shape, cuando aparece un valor 'b' lo cambia por 'bell'\n",
    "def getDescriptForEachColumns(df):\n",
    "    \n",
    "    for column in df:\n",
    "                \n",
    "        ##Attribute Information: (classes: edible=e, poisonous=p)\n",
    "        ##Decalramos a la clase como Dummies.\n",
    "        if column == 'class':\n",
    "            df[column] = df[column].replace({'e': 1},{'p': 0})\n",
    "            df.rename(columns={'class': 'edible'}, inplace=True)\n",
    "        #cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "        elif column == 'cap-shape':\n",
    "            df[column] = df[column].replace('b', 'bell')\n",
    "            df[column] = df[column].replace('c', 'conical')\n",
    "            df[column] = df[column].replace('x', 'convex')\n",
    "            df[column] = df[column].replace('f', 'flat')\n",
    "            df[column] = df[column].replace('k', 'knobbed')\n",
    "            df[column] = df[column].replace('s', 'sunken')\n",
    "            \n",
    "        #cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "        elif column == 'cap-surface':\n",
    "            df[column] = df[column].replace('f', 'fibrous')\n",
    "            df[column] = df[column].replace('g', 'grooves')\n",
    "            df[column] = df[column].replace('y', 'scaly')\n",
    "            df[column] = df[column].replace('s', 'smooth')\n",
    "        \n",
    "        #cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "        elif column == 'cap-color':\n",
    "            df[column] = df[column].replace('n', 'brown')\n",
    "            df[column] = df[column].replace('b', 'buff')\n",
    "            df[column] = df[column].replace('c', 'cinnamon')\n",
    "            df[column] = df[column].replace('g', 'gray')\n",
    "            df[column] = df[column].replace('r', 'green')\n",
    "            df[column] = df[column].replace('p', 'pink')\n",
    "            df[column] = df[column].replace('u', 'purple')\n",
    "            df[column] = df[column].replace('e', 'red')\n",
    "            df[column] = df[column].replace('w', 'white')\n",
    "            df[column] = df[column].replace('y', 'yellow')\n",
    "        \n",
    "        #bruises: bruises=t,no=f\n",
    "        #declaramos a Bruises como dummies \n",
    "        elif column == 'bruises':\n",
    "            df[column] = df[column].replace('t', 1)\n",
    "            df[column] = df[column].replace('f', 0)\n",
    "            \n",
    "        #odor: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n",
    "        elif column == 'odor':\n",
    "            df[column] = df[column].replace('a', 'almond')\n",
    "            df[column] = df[column].replace('l', 'anise')\n",
    "            df[column] = df[column].replace('c', 'creosote')\n",
    "            df[column] = df[column].replace('y', 'fishy')\n",
    "            df[column] = df[column].replace('f', 'foul')\n",
    "            df[column] = df[column].replace('m', 'musty')\n",
    "            df[column] = df[column].replace('n', 'none')\n",
    "            df[column] = df[column].replace('p', 'pungent')\n",
    "            df[column] = df[column].replace('s', 'spicy')\n",
    "                    \n",
    "        #gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "        elif column == 'gill-attachment':\n",
    "            df[column] = df[column].replace('a', 'attached')\n",
    "            df[column] = df[column].replace('d', 'descending')\n",
    "            df[column] = df[column].replace('f', 'free')\n",
    "            df[column] = df[column].replace('n', 'notched')\n",
    "        \n",
    "        #gill-spacing: close=c,crowded=w,distant=d\n",
    "        elif column == 'gill-spacing':\n",
    "            df[column] = df[column].replace('c', 'close')\n",
    "            df[column] = df[column].replace('w', 'crowded')\n",
    "            df[column] = df[column].replace('d', 'distant')\n",
    "        \n",
    "        #gill-size: broad=b,narrow=n\n",
    "        elif column == 'gill-size':\n",
    "            df[column] = df[column].replace('b', 'broad')\n",
    "            df[column] = df[column].replace('n', 'narrow')\n",
    "        \n",
    "        #gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "        elif column == 'gill-color':\n",
    "            df[column] = df[column].replace('k', 'black')\n",
    "            df[column] = df[column].replace('n', 'brown')\n",
    "            df[column] = df[column].replace('b', 'buff')\n",
    "            df[column] = df[column].replace('h', 'chocolate')\n",
    "            df[column] = df[column].replace('g', 'gray')\n",
    "            df[column] = df[column].replace('r', 'green')\n",
    "            df[column] = df[column].replace('o', 'orange')\n",
    "            df[column] = df[column].replace('p', 'pink')\n",
    "            df[column] = df[column].replace('u', 'purple')\n",
    "            df[column] = df[column].replace('e', 'red')\n",
    "            df[column] = df[column].replace('w', 'white')\n",
    "            df[column] = df[column].replace('y', 'yellow')\n",
    "        \n",
    "        #stalk-shape: enlarging=e,tapering=t\n",
    "        elif column == 'stalk-shape':\n",
    "            df[column] = df[column].replace('e', 'enlarging')\n",
    "            df[column] = df[column].replace('t', 'tapering')\n",
    "        \n",
    "        #stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\n",
    "        elif column == 'stalk-root':\n",
    "            df[column] = df[column].replace('b', 'bulbous')\n",
    "            df[column] = df[column].replace('c', 'club')\n",
    "            df[column] = df[column].replace('u', 'cup')\n",
    "            df[column] = df[column].replace('e', 'equal')\n",
    "            df[column] = df[column].replace('z', 'rhizomorphs')\n",
    "            df[column] = df[column].replace('r', 'rooted')\n",
    "            df[column] = df[column].replace('?', 'missing')\n",
    "            \n",
    "        #stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "        elif column == 'stalk-surface-above-ring':\n",
    "            df[column] = df[column].replace('f', 'fibrous')\n",
    "            df[column] = df[column].replace('y', 'scaly')\n",
    "            df[column] = df[column].replace('k', 'silky')\n",
    "            df[column] = df[column].replace('s', 'smooth')\n",
    "        \n",
    "        #stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "        elif column == 'stalk-surface-below-ring':\n",
    "            df[column] = df[column].replace('f', 'fibrous')\n",
    "            df[column] = df[column].replace('y', 'scaly')\n",
    "            df[column] = df[column].replace('k', 'silky')\n",
    "            df[column] = df[column].replace('s', 'smooth')\n",
    "        \n",
    "        #stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "        elif column == 'stalk-color-above-ring':\n",
    "            df[column] = df[column].replace('n', 'brown')\n",
    "            df[column] = df[column].replace('b', 'buff')\n",
    "            df[column] = df[column].replace('c', 'cinnamon')\n",
    "            df[column] = df[column].replace('g', 'gray')\n",
    "            df[column] = df[column].replace('o', 'orange')\n",
    "            df[column] = df[column].replace('p', 'pink')\n",
    "            df[column] = df[column].replace('e', 'red')\n",
    "            df[column] = df[column].replace('w', 'white')\n",
    "            df[column] = df[column].replace('y', 'yellow')\n",
    "        \n",
    "        #stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "        elif column == 'stalk-color-below-ring':\n",
    "            df[column] = df[column].replace('n', 'brown')\n",
    "            df[column] = df[column].replace('b', 'buff')\n",
    "            df[column] = df[column].replace('c', 'cinnamon')\n",
    "            df[column] = df[column].replace('g', 'gray')\n",
    "            df[column] = df[column].replace('o', 'orange')\n",
    "            df[column] = df[column].replace('p', 'pink')\n",
    "            df[column] = df[column].replace('e', 'red')\n",
    "            df[column] = df[column].replace('w', 'white')\n",
    "            df[column] = df[column].replace('y', 'yellow')\n",
    "\n",
    "        \n",
    "        #veil-type: partial=p,universal=u\n",
    "        elif column == 'veil-type':\n",
    "            df[column] = df[column].replace('p', 'partial')\n",
    "            df[column] = df[column].replace('u', 'universal')\n",
    "\n",
    "        #veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "        elif column == 'veil-color':\n",
    "            df[column] = df[column].replace('n', 'brown')\n",
    "            df[column] = df[column].replace('o', 'orange')\n",
    "            df[column] = df[column].replace('w', 'white')\n",
    "            df[column] = df[column].replace('y', 'yellow')\n",
    "\n",
    "        #ring-number: none=n,one=o,two=t\n",
    "        elif column == 'ring-number':\n",
    "            df[column] = df[column].replace('n', 'none')\n",
    "            df[column] = df[column].replace('o', 'one')\n",
    "            df[column] = df[column].replace('t', 'two')\n",
    "\n",
    "        #ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
    "        elif column == 'ring-type':\n",
    "            df[column] = df[column].replace('c', 'cobwebby')\n",
    "            df[column] = df[column].replace('e', 'evanescent')\n",
    "            df[column] = df[column].replace('f', 'flaring')\n",
    "            df[column] = df[column].replace('l', 'large')\n",
    "            df[column] = df[column].replace('n', 'none')\n",
    "            df[column] = df[column].replace('p', 'pendant')\n",
    "            df[column] = df[column].replace('s', 'sheathing')\n",
    "            df[column] = df[column].replace('z', 'zone')\n",
    "            \n",
    "        #spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
    "        elif column == 'spore-print-color':\n",
    "            df[column] = df[column].replace('k', 'black')\n",
    "            df[column] = df[column].replace('n', 'brown')\n",
    "            df[column] = df[column].replace('b', 'buff')\n",
    "            df[column] = df[column].replace('h', 'chocolate')\n",
    "            df[column] = df[column].replace('g', 'green')\n",
    "            df[column] = df[column].replace('o', 'orange')\n",
    "            df[column] = df[column].replace('u', 'purple')\n",
    "            df[column] = df[column].replace('w', 'white')\n",
    "            df[column] = df[column].replace('y', 'yellow')\n",
    "        \n",
    "        #population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
    "        elif column == 'population':\n",
    "            df[column] = df[column].replace('a', 'abundant')\n",
    "            df[column] = df[column].replace('c', 'clustered')\n",
    "            df[column] = df[column].replace('n', 'numerous')\n",
    "            df[column] = df[column].replace('s', 'scattered')\n",
    "            df[column] = df[column].replace('v', 'several')\n",
    "            df[column] = df[column].replace('y', 'solitary')\n",
    "\n",
    "        #habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
    "        elif column == 'habitat':\n",
    "            df[column] = df[column].replace('g', 'grasses')\n",
    "            df[column] = df[column].replace('l', 'leaves')\n",
    "            df[column] = df[column].replace('m', 'meadows')\n",
    "            df[column] = df[column].replace('p', 'paths')\n",
    "            df[column] = df[column].replace('u', 'urban')\n",
    "            df[column] = df[column].replace('w', 'waste')\n",
    "            df[column] = df[column].replace('d', 'woods')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método para imprimir información básica de las columnas del dataframe\n",
    "def getInfoByColumn(df):\n",
    "    \n",
    "    for column in df:\n",
    "        \n",
    "        InfoBasica = df[column].describe()\n",
    "        \n",
    "        uniqueValuesCount = len(df[column].unique())\n",
    "        \n",
    "        #si la columna tiene menos de 10 valores, los imprimimos sin problemas\n",
    "        #si tiene más truncamos el texto para simplificar la lectura\n",
    "        if (uniqueValuesCount < 10):\n",
    "            \n",
    "            ShowUnique = 'Show Unique  ' + str(df[column].unique()).strip('[]')\n",
    "        else:\n",
    "            ShowUnique = 'Show Unique  ' + str(df[column].unique()[0:30]).strip('[]') + ',etc...'\n",
    "        \n",
    "        print('Información columna: {} \\n''---------------\\n{}'.format(column, InfoBasica))\n",
    "        print('{}''\\n'.format(ShowUnique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método para graficar un histograma por cada columna del dataset\n",
    "def getHistogramByColumn(df):\n",
    "    for column in df:\n",
    "\n",
    "        #Gráfica Histograma:\n",
    "        Histograma = df[column].hist(grid=False, color='indigo', bins=10, xlabelsize=10, xrot=45)\n",
    "        \n",
    "        #Título y nombre de ejes: \n",
    "        plt.xlabel(column, fontsize= 13, color='green')\n",
    "        plt.ylabel('Freq.',fontsize= 13, color='green')\n",
    "        plt.title('Columna: ' + column, fontsize= 20, color='mediumslateblue')\n",
    "        \n",
    "        plt.legend(labels=df[column],  loc='upper right', fontsize='small',bbox_to_anchor=(1.3, 1))\n",
    "        plt.show()\n",
    "        print (Histograma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método para obtener datos estadísticos de cada columna del dataframe\n",
    "def getStatisticForEachColumn(df):\n",
    "    \n",
    "    for column in df:\n",
    "        \n",
    "        STD = df[column].std()\n",
    "        \n",
    "        MEAN = df[column].mean()\n",
    "        \n",
    "        VAR =  df[column].var()\n",
    "        \n",
    "        print('Statistics mesures from:{}\\n-----------------------------\\nSTD:{}\\nVAR: {}\\nMean: {}\\n'.format(column, STD, VAR, MEAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método para generar un gráfico de correlación de las variables del data frame\n",
    "def plot_corr(df,size=10):\n",
    "    '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot'''\n",
    "\n",
    "    corr = df\n",
    "    fig, ax = plt.subplots(figsize=(size, size),)\n",
    "    ax.matshow(corr)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos relacionados al modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método para obtener el hiperparámetro K más óptimo\n",
    "#useStandarization determina si se aplica o no la estandarización a los valores de los datos \n",
    "#retorna un dataframe con el score para todos los K's, cuya cantidad es determinada por quantityK\n",
    "def getScoresForHyperparameterK(quantityK, stepK, model_X_train, model_y_train, kFold_N_Splits=5, KFold_shuffle=True, useStandarization=False):\n",
    "    kf = KFold(n_splits=kFold_N_Splits, shuffle=KFold_shuffle, random_state=12)\n",
    "\n",
    "    scores_para_df = []\n",
    "    \n",
    "    #si viene configurado, se realiza la estandarización de los valores\n",
    "    if(useStandarization):\n",
    "        scaler = StandardScaler()\n",
    "        model_X_train = scaler.fit_transform(model_X_train)\n",
    "\n",
    "    for i in range(1, quantityK+1, stepK):\n",
    "\n",
    "        # En cada iteración instanciamos el modelo con un hiperparámetro distinto\n",
    "        model = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "        # cross_val_scores nos devuelve un array de 5 resultados,\n",
    "        # uno por cada partición que hizo automáticamente CV\n",
    "        cv_scores = cross_val_score(model, model_X_train, model_y_train, cv=kf)\n",
    "\n",
    "        # Para cada valor de n_neighbours, creo un diccionario con el valor\n",
    "        # de n_neighbours y la media y el desvío de los scores.\n",
    "        dict_row_score = {'score_medio':np.mean(cv_scores),\\\n",
    "                          'score_std':np.std(cv_scores), 'n_neighbours':i}\n",
    "\n",
    "        # Guardo cada uno en la lista de diccionarios\n",
    "        scores_para_df.append(dict_row_score)\n",
    "    \n",
    "    dfResult = pd.DataFrame(scores_para_df)\n",
    "    dfResult['limite_inferior'] = dfResult['score_medio'] - dfResult['score_std']\n",
    "    dfResult['limite_superior'] = dfResult['score_medio'] + dfResult['score_std']\n",
    "    \n",
    "    return dfResult\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKNNPredictions(X_train, y_train, X_test, K, useStandarization = False):\n",
    "    \n",
    "    if(useStandarization):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train) \n",
    "        X_test = scaler.transform(X_test) \n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=K)   \n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodos relacionados al modelo Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método para obtener el hiperparámetro C más óptimo\n",
    "#useStandarization determina si se aplica o no la estandarización a los valores de los datos\n",
    "#retorna un dataframe con el score para todos los C's del array valoresPosiblesC\n",
    "def getScoresForHyperparameterC(valoresPosiblesC, model_X_train, model_y_train, kFold_N_Splits=5, KFold_shuffle=True, useStandarization=False):\n",
    "    kf = KFold(n_splits=kFold_N_Splits, shuffle=KFold_shuffle, random_state=12)\n",
    "\n",
    "    scores_para_df = []\n",
    "    \n",
    "    #si viene configurado, se realiza la estandarización de los valores\n",
    "    if(useStandarization):\n",
    "        scaler = StandardScaler()\n",
    "        model_X_train = scaler.fit_transform(model_X_train)\n",
    "\n",
    "    for i in valoresPosiblesC:\n",
    "        \n",
    "        #para evitar el warning\n",
    "        #C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
    "        #se usa el parametro solver='lbfgs'\n",
    "        model = linear_model.LogisticRegression(C=i, solver='lbfgs')        \n",
    "        cv_scores = cross_val_score(model, model_X_train, model_y_train, cv=kf)\n",
    "        \n",
    "        dict_row_score = {'score_medio':np.mean(cv_scores), 'score_std':np.std(cv_scores), 'C':i}        \n",
    "        scores_para_df.append(dict_row_score)\n",
    "\n",
    "    dfResult = pd.DataFrame(scores_para_df)\n",
    "    dfResult['limite_inferior'] = dfResult['score_medio'] - dfResult['score_std']\n",
    "    dfResult['limite_superior'] = dfResult['score_medio'] + dfResult['score_std']\n",
    "    \n",
    "    return dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLogisticRegressionPredictions(X_train, y_train, X_test, C, useStandarization = False):\n",
    "    \n",
    "    if(useStandarization):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train) \n",
    "        X_test = scaler.transform(X_test) \n",
    "    \n",
    "    #para evitar el warning\n",
    "    #C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
    "    #se usa el parametro solver='lbfgs'\n",
    "    model = linear_model.LogisticRegression(C=C, solver='lbfgs')   \n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodos para Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBernoulliNaiveBayesPredictions(X_train, y_train, X_test):\n",
    "    model = BernoulliNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(y_test, y_pred, size=10):\n",
    "    \n",
    "    confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(size,size))   \n",
    "    sns.heatmap(confusionMatrix, annot=True, fmt='d',linewidths=.5,cmap=\"Blues\")\n",
    "    plt.ylabel('Valores verdaderos')\n",
    "    plt.xlabel('Valores predichos');\n",
    "    \n",
    "    return confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
