{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar bibliotecas generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as regex\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar bibliotecas propias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biblioteca para completar valores Nan de la columna rooms\n",
    "%run \"analize_description_title.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer el data set desde el archivo y generar el data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathArchivoDataSet = 'properatti.csv'\n",
    "df = pd.read_csv(pathArchivoDataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detalle generales del data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La primer columna no tiene un nombre asignado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df.index == df['Unnamed: 0']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para todas las filas del data frame, el valor de la primer columna es igual al valor del index. Se puede asumir que dicha columna corresponde a un campo ID. Se renombra la primer columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0': 'Id'}, inplace = True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se eliminan columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitamos la columna floor, ya que es difícil de inferir a partir de las demás columnas, por simplicidad se quita de los datos\n",
    "df.drop(labels='floor', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitamos la columna image_thumbnail ya que no aporta información relevante\n",
    "df = df.drop(labels='image_thumbnail', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitamos la columna properati_url ya que no aporta información relevante\n",
    "df = df.drop(labels='properati_url', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chequeamos las columnas que nos quedan\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se eliminan datos (filas) que no pudieron ser completados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se eliminan filas cuyo campo description está vacío, dicha columna se tomó como fuente para otras columnas\n",
    "#al venir vacía otros datos no pueden ser completados\n",
    "emptyDescriptionIndexes = df[df['description'].isnull()].index\n",
    "\n",
    "#borramos las filas con los correspondientes indices\n",
    "df.drop(emptyDescriptionIndexes , inplace=True)\n",
    "\n",
    "#reseteamos los índices para poder seguir usándolos sin problemas\n",
    "df.reset_index();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completar valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A partir del dato geonames_id, generamos tres columnas nuevas, que corresponden a la coordenada representativa de cada zona (representada por un geonames_id). Esta coordenada no corresponde a la de la propiedad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leemos directamente el archivo CSV generado en la notebook auxiliar \"Completar coordenadas desde geonames_id\" . Para ver el proceso remitirse a dicha notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latLngCSVFileName = 'latLngFromGeonames.csv'\n",
    "#cargamos el archivo\n",
    "latLongDF = pd.read_csv(latLngCSVFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergeamos el data frame leído con el da properatti usando el dato geonames_id\n",
    "df = df.merge(latLongDF, how='left', left_on='geonames_id', right_on='geonames_id', suffixes=('', '_geonames'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de coordenadas de propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armamos 2 DataFrame:\n",
    "    (A) 1 DataFrame para Ordenada Latitud: de columnas 'place_name' y 'lat'\n",
    "    (B) 1 DataFrame para Ordenada Longitud: de columnas 'place_name' y 'lon'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) DF de Ordenada Latitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el subset del dataframe 'data' para quedarnos sólo con las columnas 'place_name' y 'lat'\n",
    "# una vez definida se pasa el método \".head()\" que despliega las primeras 5 filas del Dataframe \n",
    "\n",
    "dflatitud=df[['place_name', 'lat']]\n",
    "dflatitud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cantidad de filas completas de la columna 'lat' en comparación al total de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflatitud.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De (A) nos quedamos solo con los campos con datos, de la columna 'lat', desechando los valores 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflatitud_1=dflatitud.dropna()\n",
    "dflatitud_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a tomar cantidad de datos por fila y vemos que se eliminaron los NaN del Dataframe.\n",
    "Observamos también, que en 'lat' bajaron 23 filas más, lo que indica que en 'place_name' también eran NaN. Se eliminan son sólo 23 en 121220 (0,018%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflatitud_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calulamos la media de las latitudes por grupo de localidad, con el método \".groupby()\" P.ej.: toma todas las filas de localidad igual a \"Abasto\", de la columna 'place_name' y calcula la media de las Latitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflatitud_1=dflatitud_1.groupby(['place_name']).mean()\n",
    "dflatitud_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que la cantidad de filas vuelve a disminuir, puesto que sólo muestra la media de localidades únicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dflatitud_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) DF de Ordenada Longitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Armo un subset sólo con las columnas 'place_name' y 'lon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el subset del dataframe 'data' para quedarnos sólo con las columnas 'place_name' y 'lat'\n",
    "# una vez definida se pasa el método \".head()\" que despliega las primeras 5 filas del Dataframe \n",
    "dflongitud=df[['place_name', 'lon']]\n",
    "dflongitud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cantidad de filas completas de la columna 'lon' en comparación al total de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflongitud.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De (B) nos quedamos solo con los campos con datos, de la columna 'lon', desechando los valores 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflongitud_1=dflongitud.dropna()\n",
    "dflongitud_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a tomar cantidad de datos por fila y vemos que se eliminaron los NaN del Dataframe.\n",
    "Observamos también, que en 'lon' bajaron 23 filas más, lo que indica que en 'place_name' también eran NaN. Se eliminan son sólo 23 en 121220 (0,018%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflongitud_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calulamos la media de las longtudes por grupo de localidad, con el método \".groupby()\" P.ej.: toma todas las filas de localidad igual a \"Abasto\", de la columna 'place_name' y calcula la media de las Longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflongitud_1=dflongitud_1.groupby(['place_name']).mean()\n",
    "dflongitud_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que la cantidad de filas vuelve a disminuir, puesto que sólo muestra la media de localidades únicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dflongitud_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un nuevo dataframe que una las columnas lat y lon de los puntos (A) y (B).\n",
    "Para ello vamos utilizar el método \".merge()\" de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflatlon=pd.merge(dflatitud_1, dflongitud_1, left_on='place_name', right_on='place_name')\n",
    "dflatlon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos al nuevo dataframe y generamos un nuevo índice para que 'place_name' vuelva a ser una variable del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflatlon.reset_index(inplace=True)\n",
    "dflatlon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos al dataframe original (df) y hacemos un Join con Pandas, sumando al final del DF las columnas con las medias de 'lat' y 'lon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dflatlon, how='left', left_on='place_name', right_on='place_name', suffixes=('','_mediaPorZona'))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de localidades: place_with_parent_names, place_name, country_name, state_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['place_with_parent_names', 'place_name','country_name','state_name']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solo faltan 23 valores en la columna 'place_name' (información de barrio, zona, ciudad, etc.) que se intentarán obtener del la columna 'place_with_parent_names'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seteamos la longitud del output para mejor lectura\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tomamos las columnas necesarias para completar los faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['place_with_parent_names', 'place_name','country_name','state_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se crea una nueva columna con los valores de la columna 'place_with_parent_names' en forma de lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disgrega(valor):\n",
    "    return valor.strip('|').split('|')\n",
    "\n",
    "df['lista_auxiliar'] = df['place_with_parent_names'].apply(lambda x: disgrega(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lista_auxiliar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se calcula cuantos elementos tiene cada lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['conteo'] = df['lista_auxiliar'].apply(lambda x: len(x))\n",
    "df['conteo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se determina cual es el mayor y menor números de elemntos en un registro de 'place_with_parent_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['conteo'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['conteo'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se necesitarán 5 columnas como máximo para desempacar las distintas jerarquías de las locaciones. Mediante el comando apply se obtienen 5 columnas extras con información de localización por regiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeo2(valor):\n",
    "    if len(valor) > 2:\n",
    "        return valor[2]\n",
    "    \n",
    "    \n",
    "def chequeo3(valor):\n",
    "    if len(valor) > 3:\n",
    "        return valor[3]\n",
    "    \n",
    "def chequeo4(valor):\n",
    "    if len(valor) > 4:\n",
    "        return valor[4]\n",
    "\n",
    "df['loc1'] = df['lista_auxiliar'].apply(lambda x: x[0])\n",
    "df['loc2'] = df['lista_auxiliar'].apply(lambda x: x[1])\n",
    "df['loc3'] = df['lista_auxiliar'].apply(lambda x: chequeo2(x))\n",
    "df['loc4'] = df['lista_auxiliar'].apply(lambda x: chequeo3(x))\n",
    "df['loc5'] = df['lista_auxiliar'].apply(lambda x: chequeo4(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daux = df[(df.loc5.notnull())]\n",
    "daux[['loc1', 'loc2', 'loc3', 'loc4', 'loc5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificamos que los registros que tenían place_name vacíos tengan valores válidos en las nuevas columnas para cubrir el faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['place_name'].isna() & ~df['loc5'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['place_name'].isna()][['lat','lon','geonames_id','place_name','place_with_parent_names', 'loc1', 'loc2', 'loc3', 'loc4', 'loc5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Property_Type => OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los tipos de propiedades existentes, y su correspondiente cantidad\n",
    "\n",
    "df['property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos si alguna linea tiene el tipo de propiedad vacio\n",
    "#Vemos que no, que todas las 121.220 lineas existentes tienen el campo completo\n",
    "\n",
    "df['property_type'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = df.loc[:, 'property_type'] == 'house'\n",
    "print(\"La cantidad de house es: \",house.sum())\n",
    "\n",
    "apartment = df.loc[:, 'property_type'] == 'apartment'\n",
    "print(\"La cantidad de apartment es: \",apartment.sum())\n",
    "\n",
    "PH = df.loc[:, 'property_type'] == 'PH'\n",
    "print(\"La cantidad de PH es: \",PH.sum())\n",
    "\n",
    "store = df.loc[:, 'property_type'] == 'store'\n",
    "print(\"La cantidad de store es: \",store.sum())\n",
    "\n",
    "tipodepropiedad = house & apartment & PH & store\n",
    "print(\"La cantidad de propiedades sin tipo es: \",tipodepropiedad.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Surface (covered y total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Opcion 1: funcion para obtener metros cuadrados (a partir de surface_total_in_m2 y surface_covered_in_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cantidad registros surface_covered_in_m2 sin valor: ' + str(df['surface_covered_in_m2'].isnull().sum()))\n",
    "print('Cantidad registros surface_total_in_m2 sin valor: ' + str(df['surface_total_in_m2'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Vamos a tratar de llenar los datos faltantes de superficie total en el dataset, rellenando con el promedio por barrio de cada publicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero vamos a ordenar el dataset para poder tener los partidos en orden y limpios\n",
    "df.rename(index=str, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero hacmemos data wrangling de la columna \"place_with_parent_names\"\n",
    "\n",
    "df.place_with_parent_names = df.place_with_parent_names.map(str.lower) #llevo a minusculas para evitar duplicados\n",
    "\n",
    "grouped_places = df.groupby(['place_with_parent_names']) #agrupo por place_with_parent_names\n",
    "\n",
    "dictio_places = grouped_places.groups.keys() #genero diccionario de places\n",
    "\n",
    "cantidad_places = len(dictio_places) #cuento la cantidad de places distintos\n",
    "\n",
    "print(\"Cantidad de place_with_parent_names distintos: \",cantidad_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_x_places = grouped_places.agg({\"Id\": \"count\"}) #agrupo y cuento\n",
    "\n",
    "count_x_places = count_x_places.rename(index=str, columns={\"Id\": \"cantidad\"}) #renombro la columna por cantidad\n",
    "\n",
    "count_x_places = count_x_places.sort_values(by=['cantidad'], ascending=False) #ordeno por cantidad descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count_x_places.query(\"cantidad > 50\")) # places con mas de <n> registros. Solo consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_places = [sub_places.split('|') for sub_places in count_x_places.index]\n",
    "\n",
    "df_places = pd.DataFrame(list_places, \n",
    "                         index = count_x_places.index, \n",
    "                         columns =['none1','pais','provincia','partido','localidad','barrio','none2'])\n",
    "\n",
    "df_places = df_places.drop(['none1', 'none2'], axis=1) # elimino none1 y none2\n",
    "df_places = df_places.drop(['pais'], axis=1) # elimino pais ya que todos son argentina\n",
    "df_places[df_places.barrio.notnull()] # el unico que tiene barrios es tigre-nordelta\n",
    "df_places = df_places.drop(['barrio'], axis=1) # elimino barrio tambien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada columna busco vacios y asigno None\n",
    "\n",
    "for column_name in df_places.columns:\n",
    "    df_places[column_name][df_places[column_name].apply(lambda column_name: True if regex.search('^\\s*$', str(column_name)) else False)]=None\n",
    "\n",
    "df_places = df_places.sort_values(by=['provincia','partido','localidad']) #ordeno\n",
    "\n",
    "# creo df de provincias partidos y localidades\n",
    "df_provincias = pd.DataFrame(df_places.provincia.unique(),columns=['nombre'])\n",
    "df_partidos = pd.DataFrame(df_places.partido.unique(),columns=['nombre'])\n",
    "df_localidades = pd.DataFrame(df_places.localidad.unique(),columns=['nombre'])\n",
    "\n",
    "def buscar_reemplazar_place_column(row,column_name,df_base):\n",
    "    if row[column_name]:\n",
    "        idx = df_base.index[df_base.nombre == row[column_name]]\n",
    "        return int(idx.data[0])\n",
    "    \n",
    "df_places.provincia =  df_places.apply(buscar_reemplazar_place_column,args=('provincia',df_provincias),axis=1)\n",
    "df_places.partido =  df_places.apply(buscar_reemplazar_place_column,args=('partido',df_partidos),axis=1)\n",
    "df_places.localidad =  df_places.apply(buscar_reemplazar_place_column,args=('localidad',df_localidades),axis=1)\n",
    "df_places.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrega la relacion para las columnas que se vayan pasando respecto al dataframe de provincias, localidades y partidos\n",
    "\n",
    "def agregar_columna_place(row,column_name,test):\n",
    "    if (row.place_with_parent_names):\n",
    "        return df_places.loc[row.place_with_parent_names][column_name]\n",
    "    \n",
    "provincias = df.apply(agregar_columna_place,args=('provincia','random'),axis=1)\n",
    "df['provincia'] = pd.Series(provincias, index=df.index)\n",
    "partidos = df.apply(agregar_columna_place,args=('partido','random'),axis=1)\n",
    "df['partido'] = pd.Series(partidos, index=df.index)\n",
    "localidades = df.apply(agregar_columna_place,args=('localidad','random'),axis=1)\n",
    "df['localidad'] = pd.Series(localidades, index=df.index)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['provincia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis del cambio de columnas realizado con place_with parent names\n",
    "\n",
    "df.place_name = df.place_name[df.place_name.notnull()].map(str.lower)\n",
    "df_place_name = df.place_name\n",
    "\n",
    "df_place_name_not_in = df_place_name[~(df_place_name.isin(df_partidos.nombre))]\n",
    "df_place_name_not_in_loc = df_place_name_not_in[~(df_place_name_not_in.isin(df_localidades.nombre))]\n",
    "df_place_name_not_in_loc_prov = df_place_name_not_in_loc[~(df_place_name_not_in_loc.isin(df_provincias.nombre))]\n",
    "df_place_name_not_in_loc_prov.unique()\n",
    "#Puedo eliminar la columna place_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazo los valores que encuentro en place_name y que estan definidos en partidos\n",
    "\n",
    "df.place_name = df.place_name[df.place_name.notnull()].map(str.lower)\n",
    "\n",
    "def buscar_reemplazar_place_definidos(row,column_name,df_base): # funcion que buscar y reemplaza de la columna base (provincia, localidad, partido)\n",
    "    a = df_base.nombre.str.contains(row[column_name], regex=False).any()\n",
    "    if a:\n",
    "        idx = df_base.index[df_base.nombre == row[column_name]]\n",
    "        return int(idx.data[0])\n",
    "    \n",
    "df_place_name = df.place_name\n",
    "mask_in_partidos = (df_place_name.isin(df_partidos.nombre))\n",
    "mask_not_column_partido = df.partido.isnull()\n",
    "\n",
    "print(\"Partidos con null:\" + str(df.partido.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reemplazar_part = df[mask_not_column_partido&mask_in_partidos].apply(buscar_reemplazar_place_definidos,args=('place_name',df_partidos),axis=1)\n",
    "df.partido.update(df_reemplazar_part)\n",
    "print(\"Partidos con null luego de procesar:\" + str(df.partido.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazo los valores que encuentro en place_name y que estan definidos en localidades\n",
    "\n",
    "df_place_name = df.place_name\n",
    "mask_in_localidades = (df_place_name.isin(df_localidades.nombre))\n",
    "mask_not_column_localidad = df.localidad.isnull()\n",
    "\n",
    "print(\"Localidades con null: \" + str(df.localidad.isna().sum()))\n",
    "\n",
    "df_reemplazar_loc = df[mask_not_column_localidad&mask_in_localidades].apply(buscar_reemplazar_place_definidos,args=('place_name',df_localidades),axis=1)\n",
    "df.localidad.update(df_reemplazar_loc)\n",
    "\n",
    "print(\"Localidades con null luego de procesar: \" + str(df.localidad.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ahora vamos a limpiar la columna surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df[df.title.notnull()]\n",
    "df_title.title = df_title.title.map(str.lower)\n",
    "pattern_m2 = regex.compile(\"(\\d+\\s*) m2\")\n",
    "\n",
    "def get_m2(row):\n",
    "    result = pattern_m2.search(row)\n",
    "    try:\n",
    "        str_aux = result.group(1)\n",
    "        array_m2 = str_aux.split()\n",
    "        m2 = array_m2[-1]\n",
    "        try:\n",
    "            m2 = float(m2)\n",
    "            return m2\n",
    "        except:\n",
    "            return np.nan;\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "print(\"Cantidad de nulos m2 total surface: \",df.surface_total_in_m2.isnull().sum())\n",
    "\n",
    "m2_from_title = df_title.title.apply(get_m2)\n",
    "m2_from_title[m2_from_title.notnull()]\n",
    "df.surface_total_in_m2.update(m2_from_title)\n",
    "\n",
    "print(\"Cantidad de nulos luego de procesar: \",df.surface_total_in_m2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a generar los 39.328 datos faltantes en surface_total en la tabla, y lo vamos a hacer\n",
    "#rellenando con el promedio del barrio de cada propiedad\n",
    "\n",
    "print(\"Cantidad de nulos en surface_total_in_m2 antes:\",df.surface_total_in_m2.isnull().sum())\n",
    "\n",
    "# creamos una proporción de metros cubiertos sobre metros totales - no puede ser mayor a 1!\n",
    "propcubierto = df.surface_covered_in_m2 / df.surface_total_in_m2\n",
    "mask = propcubierto < 1\n",
    "propcubierto_clean  = propcubierto[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relevamos algunos casos anómalos, donde la proporción da mayor a uno (inverosímil). Desestimamos estos 1200 registros para este procedimiento.\n",
    "tempmask = propcubierto > 1\n",
    "np.sum(tempmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una nueva variable sin esos datos anómalos\n",
    "mask = propcubierto < 1\n",
    "propcubierto_clean  = propcubierto[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hay dos casos anómalos donde superficie cubierta es cero, los reemplazamos por np.nan para evitar conflictos en el siguiente paso.\n",
    "masksurface0 = (df.surface_covered_in_m2 == 0)\n",
    "df.surface_covered_in_m2[masksurface0].fillna(np.nan)\n",
    "\n",
    "#Agregamos la columna al dataframe\n",
    "df['propcubierto']=propcubierto_clean\n",
    "\n",
    "#Agrupamos por provincia(partido) el porcentaje promedio de m2cubierto/m2total\n",
    "avg_propcubiertobarrio = df.groupby('partido')[\"propcubierto\"].mean().sort_values(ascending = False)\n",
    "\n",
    "#Cantidad de datos para calcular la proporcion \n",
    "avg_propcubiertobarriocount = df.groupby('partido')[\"propcubierto\"].count().sort_values(ascending = False)\n",
    "\n",
    "#Condición de la regla 1\n",
    "removerporcantidadmask = avg_propcubiertobarriocount > 30\n",
    "\n",
    "#Cantidad de datos existentes en tabla\n",
    "datos_en_tabla = df.groupby('partido')['partido'].count().sort_values(ascending = False)\n",
    "\n",
    "#Divido los datos existentes sobre los datos totales y obtengo la relación para la regla DOS\n",
    "proporcion = avg_propcubiertobarriocount / datos_en_tabla\n",
    "proporcion.round(2).sort_values(ascending = True)\n",
    "\n",
    "#Condición de la regla 2\n",
    "removerporproporcionmask = proporcion > 0.25\n",
    "\n",
    "#Genero máscara con ambas condiciones\n",
    "proporcionmask2 = removerporcantidadmask & removerporproporcionmask\n",
    "propvalidados = avg_propcubiertobarrio[proporcionmask2]\n",
    "\n",
    "#Ahora iteramos por las propiedades que tienen el dato faltante de superficie total y les inputamos la proporción promedio\n",
    "#del barrio al que pertenecen, usando como dato la superficie cubierta.\n",
    "# SUPERFICIE TOTAL = (SUPERFICIE CUBIERTA / PROPORCION CUBIERTO TOTAL)\n",
    "\n",
    "surface_total_in_m2_clean = []\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    if pd.isnull(row.surface_total_in_m2):    \n",
    "        if(row.partido in propvalidados.index):        \n",
    "            surface_total_in_m2_clean.append(row.surface_covered_in_m2 / propvalidados.loc[row.partido]) #VERSION CON PROPVALIDADOS NO CORRE\n",
    "        else:\n",
    "            surface_total_in_m2_clean.append(row.surface_total_in_m2)    \n",
    "    else:\n",
    "        surface_total_in_m2_clean.append(row.surface_total_in_m2)\n",
    "df[\"surface_total_in_m2_nueva\"] = surface_total_in_m2_clean\n",
    "df[\"surface_total_in_m2_nueva\"]\n",
    "\n",
    "#dropeamos los casos NaN\n",
    "surfacetotalnueva_condatos = df.surface_total_in_m2_nueva.dropna()\n",
    "\n",
    "#y finalmente, los reemplazamos en la columna \"surface_total_in_m2_nueva\" original del DF\n",
    "df.surface_total_in_m2.update(surfacetotalnueva_condatos)\n",
    "\n",
    "print(\"Cantidad de nulos en surface_total_in_m2 despues:\",df.surface_total_in_m2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.surface_total_in_m2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Completar el valor del campo rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completarValoresFaltantesEnFila(dataFrameRow):\n",
    "    \n",
    "    ##############################################################\n",
    "    ##Actualizacion de Rooms utilizando el método definido en la notebbok auxiliar fill_column_rooms (entrega 1).ipynb\n",
    "    updatedDataFameRow = updateRoomsFromRowData(dataFrameRow)\n",
    "        \n",
    "    return updatedDataFameRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(completarValoresFaltantesEnFila, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Datos en las columnas description y title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cantidad de registros description con valor nulo: ' + str(df.description.isna().sum()))\n",
    "print('Cantidad de registros title con valor nulo: ' + str(df.title.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Columna price_usd_per_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos un diccionario con valores de conversion entre monedas locales y el USD\n",
    "conversion_USD_a_monedas_locales = { 'ARS': 63, 'PEN': 3.53, 'UYU': 43.41, 'USD': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que recibe una fila del data frame y un diccionario con las conversiones entre monedas locales y el USD\n",
    "#este metodo intenta calcular el precio por m2 en USD a partir de otras columnas del data frame\n",
    "def updatePriceUSDPerM2(dataFrameRow, dolarConversion):\n",
    "    \n",
    "    conversion = 1\n",
    "    \n",
    "    #si el dato currency no tiene valor, asumimos que los valores son en USD (conversion = 1)\n",
    "    #si currency tiene un valor, obtenemos el valor de conversion desde el diccionario dolarConversion\n",
    "    if(not pd.isnull(dataFrameRow.currency)):\n",
    "        conversion = dolarConversion[dataFrameRow.currency]\n",
    "    \n",
    "    #completamos solamente si la columna no tiene valor\n",
    "    if(math.isnan(dataFrameRow.price_usd_per_m2)):\n",
    "        #precio por m2 USD= precio total USD / superficie total\n",
    "        if(not math.isnan(dataFrameRow.price_aprox_usd) and not math.isnan(dataFrameRow.surface_total_in_m2) and dataFrameRow.surface_total_in_m2 != 0):\n",
    "            dataFrameRow.price_usd_per_m2 = dataFrameRow.price_aprox_usd / dataFrameRow.surface_total_in_m2\n",
    "        \n",
    "        #precio por m2 USD = (precio total $ * conversion moneda) / superficie total        \n",
    "        if(math.isnan(dataFrameRow.price_usd_per_m2) \n",
    "           and not math.isnan(dataFrameRow.price) and not math.isnan(dataFrameRow.surface_total_in_m2) and dataFrameRow.surface_total_in_m2 != 0):\n",
    "            dataFrameRow.price_usd_per_m2 = (dataFrameRow.price * conversion) / dataFrameRow.surface_total_in_m2\n",
    "    \n",
    "        #precio por m2 USD = precio por m2 * conversion moneda\n",
    "        if(math.isnan(dataFrameRow.price_usd_per_m2) \n",
    "           and not math.isnan(dataFrameRow.price_per_m2)):\n",
    "            dataFrameRow.price_usd_per_m2 = dataFrameRow.price_per_m2 * conversion\n",
    "            \n",
    "        #precio por m2 USD = precio aprox por m2 USD / superficie total\n",
    "        if(math.isnan(dataFrameRow.price_usd_per_m2) \n",
    "           and not math.isnan(dataFrameRow.price_aprox_usd) and not math.isnan(dataFrameRow.surface_total_in_m2) and dataFrameRow.surface_total_in_m2 != 0):\n",
    "            dataFrameRow.price_usd_per_m2 = dataFrameRow.price_aprox_usd / dataFrameRow.surface_total_in_m2\n",
    "            \n",
    "        #precio por m2 USD = precio aprox por m2 local currency * conversion moenda / superficie total\n",
    "        if(math.isnan(dataFrameRow.price_usd_per_m2) \n",
    "           and not math.isnan(dataFrameRow.price_aprox_local_currency) and not math.isnan(dataFrameRow.surface_total_in_m2) and dataFrameRow.surface_total_in_m2 != 0):\n",
    "            dataFrameRow.price_usd_per_m2 = (dataFrameRow.price_aprox_local_currency * conversion) / dataFrameRow.surface_total_in_m2\n",
    "            \n",
    "    return dataFrameRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contamos price per m2 en USD antes de la ejecucion\n",
    "df['price_usd_per_m2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicamos la funcion que actualiza los precios por m2 al data frame\n",
    "df = df.apply(updatePriceUSDPerM2, axis=1, dolarConversion=conversion_USD_a_monedas_locales);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificamos la cantidad de vacíos luego de la ejecución\n",
    "df['price_usd_per_m2'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Columna price_per_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar al calculo del m2 por USD, el calculo del m2 en moneda local usa otras columnas del data frame para obtener el valor\n",
    "#recibe tambien un diccionario con la conversion de monedas locales a USD\n",
    "def updatePricePerM2(dataFrameRow, dolarConversion):\n",
    "            \n",
    "    #si el dato currency no tiene valor, asumimos que el valor precio por m2 a guardar es en ARS\n",
    "    conversion = 1 / dolarConversion['ARS'] #si el dolar esta a 65 ARS => el factor de conversión de USD a ARS es 1 / 65\n",
    "    \n",
    "    #si currency tiene un valor, obtenemos el valor de conversion desde el diccionario dolarConversion\n",
    "    if(not pd.isnull(dataFrameRow.currency)):\n",
    "        conversion = 1 / dolarConversion[dataFrameRow.currency]\n",
    "    \n",
    "    #completamos solamente si la columna no tiene valor\n",
    "    if(math.isnan(dataFrameRow.price_per_m2)):\n",
    "        #precio por m2 = precio aprox total local currency / superficie total\n",
    "        if(not math.isnan(dataFrameRow.price_aprox_local_currency) and not math.isnan(dataFrameRow.surface_total_in_m2) and dataFrameRow.surface_total_in_m2 != 0):\n",
    "            dataFrameRow.price_usd_per_m2 = dataFrameRow.price_aprox_local_currency / dataFrameRow.surface_total_in_m2\n",
    "        \n",
    "        #precio por m2 = precio por m2 USD / conversion moneda\n",
    "        if(math.isnan(dataFrameRow.price_per_m2) \n",
    "           and not math.isnan(dataFrameRow.price_usd_per_m2)):\n",
    "            dataFrameRow.price_per_m2 = dataFrameRow.price_usd_per_m2 / conversion\n",
    "            \n",
    "        #precio por m2 USD = (precio aprox por m2 USD / conversion) / superficie total\n",
    "        if(math.isnan(dataFrameRow.price_per_m2) \n",
    "           and not math.isnan(dataFrameRow.price_aprox_usd) and not math.isnan(dataFrameRow.surface_total_in_m2) and dataFrameRow.surface_total_in_m2 != 0):\n",
    "            dataFrameRow.price_per_m2 = (dataFrameRow.price_aprox_usd / conversion) / dataFrameRow.surface_total_in_m2\n",
    "             \n",
    "    return dataFrameRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contamos price per m2 en USD antes de la ejecucion\n",
    "df['price_per_m2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicamos la funcion que actualiza los precios por m2 al data frame\n",
    "df = df.apply(updatePricePerM2, axis=1, dolarConversion=conversion_USD_a_monedas_locales);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificamos la cantidad de vacíos luego de la ejecución\n",
    "df['price_per_m2'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregamos algunos datos de amenities analizando las columnas description y title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los métodos que aplican las regex sobre las columnas description y title están definidos en la notebook auxiliar analize_description_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pileta'] = df.apply(lambda row: containsPool(row), axis = 1)\n",
    "df['pileta'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cochera'] = df.apply(lambda row: containsParking(row), axis = 1)\n",
    "df['cochera'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balcon'] = df.apply(lambda row: containsBalcony(row), axis = 1)\n",
    "df['balcon'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['terraza'] = df.apply(lambda row: containsTerrace(row), axis = 1)\n",
    "df['terraza'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parrilla'] = df.apply(lambda row: containsGrill(row), axis = 1)\n",
    "df['parrilla'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
