{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import maxsize #para imprimir arrays completos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing #para normalizar datos\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV, ElasticNetCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metodo para devolver un subset de datos, filtrando por state_name\n",
    "def getSubDataFrameByStateName(sourceDataframe, state_name):\n",
    "    df_result = sourceDataframe[sourceDataframe['state_name'] == state_name]\n",
    "    \n",
    "    #dropeamos la columna state_name, ya que en el df result todos pertenecen a la misma zona\n",
    "    df_result = df_result.drop(labels='state_name', axis = 1)\n",
    "    \n",
    "    #mostramos informacion del df result\n",
    "    print('Sub data frame Info: \\n')\n",
    "    print(df_result.info())\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    \n",
    "    print('Sub data frame Head: \\n')\n",
    "    print(df_result.head(5))\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeCategoricalData(dataFrame, categoricalVariablesArray):\n",
    "    for category in categoricalVariablesArray:\n",
    "        print(dataFrame[category].value_counts())\n",
    "        plt.bar(dataFrame[category].value_counts().index, dataFrame[category].value_counts().values, color='b',\\\n",
    "                alpha=0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDummiesForVariables(dataFrame, categoricalVariablesArray):\n",
    "    for category in categoricalVariablesArray:\n",
    "        serie = dataFrame[category]\n",
    "        dummies = pd.get_dummies(serie, drop_first= True, prefix=category)\n",
    "        dataFrame = pd.concat([dataFrame, dummies], axis=1)\n",
    "    \n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genera un dataframe auxiliar para mantener la relacion entre los las variables categoricas originales y los respectivos\n",
    "#dummies generados\n",
    "def generateAuxiliarDataFrameForDummies(sourceDataFrame, dummiesColsPrefix):\n",
    "    filter_col = [col for col in sourceDataFrame if col.startswith(dummiesColsPrefix)]\n",
    "    dummies = sourceDataFrame[filter_col]\n",
    "    dummies = dummies.loc[:,~dummies.columns.duplicated()]\n",
    "    dummies = dummies.drop_duplicates()\n",
    "    return dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metodo para generar una regresion lineal simple\n",
    "def generateSimpleLinearRegression(X_train, X_test, y_train, y_test, cv):\n",
    "    regresionLineal = LinearRegression()\n",
    "    \n",
    "    #normalizamos los datos de training\n",
    "    stdScaler = StandardScaler()\n",
    "    X_train_norm = stdScaler.fit_transform(X=X_train)\n",
    "    X_test_norm =  stdScaler.transform(X=X_test)\n",
    "    \n",
    "    regresionLineal_model = regresionLineal.fit(X_train_norm, y_train)\n",
    "    \n",
    "    #print('Score regresión lineal sin k-fold:', regresionLineal_model.score(X_test_norm, y_test))\n",
    "    #scores_cv = cross_validate(estimator=regresionLineal_model, X=X_test_norm, y=y_test, cv=cv, return_train_score=True)\n",
    "    \n",
    "    scores_cv = cross_val_score(regresionLineal_model, X_train_norm, y_train, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "    \n",
    "    print('Score regresión lineal sin k-fold:', scores_cv)\n",
    "    \n",
    "    #vemos los coeficientes y el interceptor obtenidos\n",
    "    print ('\\n\\n')\n",
    "    print ('Intercept: ')    \n",
    "    print (regresionLineal_model.intercept_)\n",
    "    print ('\\n\\n')\n",
    "    print ('Coeficientes: ')    \n",
    "    print (regresionLineal_model.coef_)\n",
    "    print ('\\n\\n')\n",
    "    \n",
    "    #intentamos predecir\n",
    "    regresionLineal_predicciones = regresionLineal_model.predict(X_test_norm)        \n",
    "    \n",
    "    #pasamos la Serie correspondiente a y_test a un array, para poder comparar luego los errores entre lo predicho \n",
    "    #contra los valores reales\n",
    "    y_test_array = y_test.array\n",
    "    \n",
    "    print ('MAE:', metrics.mean_absolute_error(y_test_array, regresionLineal_predicciones))\n",
    "    print ('MSE:', metrics.mean_squared_error(y_test, regresionLineal_predicciones))\n",
    "    print ('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, regresionLineal_predicciones)))\n",
    "    print ('R2:', metrics.r2_score(y_test, regresionLineal_predicciones))\n",
    "    \n",
    "    #generamos un data frame auxiliar con los valores reales, los predichos y la diferencia entre ellos\n",
    "    df_regresion_lineal_prediccion_vs_real = pd.DataFrame({'Real': y_test, \\\n",
    "                                                       'Predichos': regresionLineal_predicciones.flatten()})\n",
    "    df_regresion_lineal_prediccion_vs_real['Diferencia'] = df_regresion_lineal_prediccion_vs_real['Real'] - \\\n",
    "                                                        df_regresion_lineal_prediccion_vs_real['Predichos']\n",
    "    \n",
    "    #retorna el modelo generado, las predicciones y el data frame que compara los valores reales con los predichos\n",
    "    return regresionLineal_model, regresionLineal_predicciones, df_regresion_lineal_prediccion_vs_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metodo para generar un Ridge CV\n",
    "def generateRidgeCV(X_train, X_test, y_train, y_test, alphasArray, cv):\n",
    "    \n",
    "    lm_ridge = RidgeCV(alphas=alphasArray, normalize=False, cv=cv) \n",
    "    \n",
    "    #normalizamos los datos de training\n",
    "    stdScaler = StandardScaler()\n",
    "    X_train_norm = stdScaler.fit_transform(X=X_train)\n",
    "    X_test_norm =  stdScaler.transform(X=X_test)\n",
    "    \n",
    "    model_ridge = lm_ridge.fit(X_train_norm, y_train)\n",
    "     \n",
    "    print('Score Ridge CV:', model_ridge.score(X_test_norm, y_test))\n",
    "    \n",
    "    print('Alpha Ridge CV:', model_ridge.alpha_)\n",
    "        \n",
    "    print ('Coeficientes: ', model_ridge.coef_)\n",
    "    \n",
    "    \n",
    "    #intentamos predecir\n",
    "    RidgeCV_predicciones = model_ridge.predict(X_test_norm)\n",
    "\n",
    "    #pasamos la Serie correspondiente a y_test a un array, para poder comparar luego los errores entre lo predicho \n",
    "    #contra los valores reales\n",
    "    y_test_array = y_test.array\n",
    "    \n",
    "    print ('MAE:', metrics.mean_absolute_error(y_true=y_test_array, y_pred=RidgeCV_predicciones))\n",
    "    print ('MSE:', metrics.mean_squared_error(y_test, RidgeCV_predicciones))\n",
    "    print ('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, RidgeCV_predicciones)))\n",
    "    print ('R2:', metrics.r2_score(y_test, RidgeCV_predicciones))\n",
    "        \n",
    "    #generamos un data frame auxiliar con los valores reales, los predichos y la diferencia entre ellos\n",
    "    df_ridge_prediccion_vs_real = pd.DataFrame({'Real': y_test, \\\n",
    "                                           'Predichos': RidgeCV_predicciones.flatten()})\n",
    "    df_ridge_prediccion_vs_real['Diferencia'] = df_ridge_prediccion_vs_real['Real'] - \\\n",
    "                                                            df_ridge_prediccion_vs_real['Predichos']\n",
    "    \n",
    "    #retorna el modelo generado, las predicciones y el data frame que compara los valores reales con los predichos\n",
    "    return model_ridge, RidgeCV_predicciones,df_ridge_prediccion_vs_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metodo para generar un Ridge CV\n",
    "def generateLassoCV(X_train, X_test, y_train, y_test, alphasArray, cv):\n",
    "    \n",
    "    #normalizamos los datos de training\n",
    "    stdScaler = StandardScaler()\n",
    "    X_train_norm = stdScaler.fit_transform(X=X_train)\n",
    "    X_test_norm =  stdScaler.transform(X=X_test)\n",
    "    \n",
    "    #ejecutamos el LassoCV, usando el cross validation definido anteriormente con 5 iteraciones\n",
    "    model_lasso = LassoCV().fit(X_train_norm, y_train)\n",
    "    scores_lasso = cross_val_score(model_lasso, X_train_norm, y_train, cv=cv, scoring='r2')\n",
    "    dict(alpha=model_lasso.alpha_, scores=scores_lasso, mean_score=scores_lasso.mean(), zero_coefs=(model_lasso.coef_ == 0).sum())\n",
    "    \n",
    "    print ('\\n\\n')\n",
    "    print ('Intercept: ')\n",
    "    print ('\\n\\n')\n",
    "    print (model_lasso.intercept_)\n",
    "    print ('\\n\\n')\n",
    "    print ('Coeficientes: ')\n",
    "    print ('\\n\\n')\n",
    "    print (model_lasso.coef_)\n",
    "    print ('\\n\\n')\n",
    "    \n",
    "    #intentamos predecir\n",
    "    LassoCV_predicciones = model_lasso.predict(X_test_norm)\n",
    "    \n",
    "      #pasamos la Serie correspondiente a y_test a un array, para poder comparar luego los errores entre lo predicho \n",
    "    #contra los valores reales\n",
    "    y_test_array = y_test.array\n",
    "    \n",
    "    print ('MAE:', metrics.mean_absolute_error(y_true=y_test_array, y_pred=LassoCV_predicciones))\n",
    "    print ('MSE:', metrics.mean_squared_error(y_test, LassoCV_predicciones))\n",
    "    print ('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, LassoCV_predicciones)))\n",
    "    print ('R2:', metrics.r2_score(y_test, LassoCV_predicciones))\n",
    "    \n",
    "    #generamos un data frame auxiliar con los valores reales, los predichos y la diferencia entre ellos\n",
    "    df_lasso_prediccion_vs_real = pd.DataFrame({'Real': y_test, \\\n",
    "                                           'Predichos': LassoCV_predicciones.flatten()})\n",
    "    df_lasso_prediccion_vs_real['Diferencia'] = df_lasso_prediccion_vs_real['Real'] - \\\n",
    "                                                            df_lasso_prediccion_vs_real['Predichos']\n",
    "    df_lasso_prediccion_vs_real\n",
    "\n",
    "        \n",
    "    #retorna el modelo generado, las predicciones y el data frame que compara los valores reales con los predichos\n",
    "    return model_lasso,LassoCV_predicciones, df_lasso_prediccion_vs_real"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
